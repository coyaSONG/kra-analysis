#!/usr/bin/env python3
"""
ì „ì²´ ìˆ˜ì§‘ëœ ê²½ì£¼ì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸ í‰ê°€
"""

import json
import subprocess
import sys
import time
from datetime import datetime
from pathlib import Path


class FullEvaluator:
    def __init__(self, prompt_version: str, prompt_path: str):
        self.prompt_version = prompt_version
        self.prompt_path = prompt_path
        self.results_dir = Path("data/full_evaluation")
        self.results_dir.mkdir(parents=True, exist_ok=True)

    def find_all_result_files(self) -> list[Path]:
        """ëª¨ë“  ê²°ê³¼ íŒŒì¼ ì°¾ê¸°"""
        result_files = []
        for month_dir in Path("data/raw/results/2025").iterdir():
            if month_dir.is_dir():
                files = sorted(month_dir.glob("race_*.json"))
                result_files.extend(files)

        print(f"ì´ {len(result_files)}ê°œ ê²½ì£¼ íŒŒì¼ ë°œê²¬")
        return result_files

    def prepare_race_data(self, result_file: Path) -> dict:
        """ê²°ê³¼ íŒŒì¼ì—ì„œ ì˜ˆì¸¡ìš© ë°ì´í„° ìƒì„± (ê²°ê³¼ ì œê±°)"""
        try:
            with open(result_file, encoding="utf-8") as f:
                data = json.load(f)

            # ê²°ê³¼ ì •ë³´ ì œê±°
            prediction_data = {"race_info": data["race_info"].copy(), "horses": []}

            # ê²°ê³¼ í•„ë“œ ì œê±°
            for horse in data["horses"]:
                horse_data = horse.copy()
                # ê²°ê³¼ ê´€ë ¨ í•„ë“œ ì œê±°
                for field in ["result", "ord", "rc_time", "win_odds", "plc_odds"]:
                    if field in horse_data:
                        del horse_data[field]
                prediction_data["horses"].append(horse_data)

            return prediction_data
        except Exception as e:
            print(f"Error preparing {result_file}: {e}")
            return None

    def run_prediction_batch(self, race_files: list[Path], batch_size: int = 10):
        """ë°°ì¹˜ë¡œ ì˜ˆì¸¡ ì‹¤í–‰"""
        total_races = 0
        successful_predictions = 0
        total_correct_horses = 0
        partial_correct_1 = 0  # 1ë§ˆë¦¬ ì ì¤‘
        partial_correct_2 = 0  # 2ë§ˆë¦¬ ì ì¤‘

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ì§„í–‰ ìƒí™© íŒŒì¼
        progress_file = self.results_dir / f"progress_{timestamp}.json"
        results_file = (
            self.results_dir / f"full_evaluation_{self.prompt_version}_{timestamp}.json"
        )

        all_results = []

        # í”„ë¡¬í”„íŠ¸ ì½ê¸°
        with open(self.prompt_path, encoding="utf-8") as f:
            prompt_template = f.read()

        print(f"\nì „ì²´ í‰ê°€ ì‹œì‘: {len(race_files)}ê°œ ê²½ì£¼")
        print("=" * 60)

        for i in range(0, len(race_files), batch_size):
            batch = race_files[i : i + batch_size]
            batch_results = []

            print(
                f"\në°°ì¹˜ {i // batch_size + 1}/{(len(race_files) - 1) // batch_size + 1} ì²˜ë¦¬ ì¤‘..."
            )

            for j, result_file in enumerate(batch):
                race_id = result_file.stem
                current_idx = i + j + 1

                print(
                    f"[{current_idx}/{len(race_files)}] {race_id} ", end="", flush=True
                )

                # ì˜ˆì¸¡ìš© ë°ì´í„° ì¤€ë¹„
                race_data = self.prepare_race_data(result_file)
                if not race_data:
                    print("âŒ (ë°ì´í„° ì˜¤ë¥˜)")
                    continue

                # ê°„ì†Œí™”ëœ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                prompt = f"""{prompt_template}

ê²½ì£¼ ë°ì´í„°:
```json
{json.dumps(race_data, ensure_ascii=False, indent=2)}
```

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì œê³µí•˜ì„¸ìš”:
{{
  "selected_horses": [
    {{"chul_no": ë²ˆí˜¸, "hr_name": "ë§ì´ë¦„"}},
    {{"chul_no": ë²ˆí˜¸, "hr_name": "ë§ì´ë¦„"}},
    {{"chul_no": ë²ˆí˜¸, "hr_name": "ë§ì´ë¦„"}}
  ],
  "confidence": 70,
  "reasoning": "ê°„ë‹¨í•œ ì´ìœ "
}}"""

                try:
                    # Claude CLI ì‹¤í–‰
                    cmd = ["claude", "-p", prompt]
                    result = subprocess.run(
                        cmd, capture_output=True, text=True, timeout=120
                    )

                    if result.returncode != 0:
                        print("âŒ (CLI ì˜¤ë¥˜)")
                        continue

                    # ê²°ê³¼ íŒŒì‹±
                    output = result.stdout.strip()
                    import re

                    # íŒ¨í„´ 1: ì½”ë“œë¸”ë¡ ë‚´ JSON
                    code_block_match = re.search(
                        r"```(?:json)?\s*(\{.*?\})\s*```", output, re.DOTALL
                    )
                    if code_block_match:
                        try:
                            prediction = json.loads(code_block_match.group(1))
                        except Exception:
                            print("âŒ (íŒŒì‹± ì˜¤ë¥˜)")
                            continue
                    else:
                        # íŒ¨í„´ 2: ì¼ë°˜ JSON
                        json_match = re.search(r"\{.*\}", output, re.DOTALL)
                        if json_match:
                            try:
                                prediction = json.loads(json_match.group())
                            except Exception:
                                print("âŒ (íŒŒì‹± ì˜¤ë¥˜)")
                                continue
                        else:
                            print("âŒ (íŒŒì‹± ì˜¤ë¥˜)")
                            continue

                    # ì‹¤ì œ ê²°ê³¼ ì¶”ì¶œ
                    with open(result_file, encoding="utf-8") as f:
                        full_data = json.load(f)

                    actual_result = []
                    for horse in full_data["horses"]:
                        if "result" in horse and 1 <= horse["result"]["ord"] <= 3:
                            actual_result.append(
                                (horse["result"]["ord"], horse["chul_no"])
                            )
                    actual_result.sort()
                    actual_nums = [x[1] for x in actual_result[:3]]

                    # ì˜ˆì¸¡ ê²°ê³¼ ì¶”ì¶œ
                    predicted_horses = [
                        h["chul_no"] for h in prediction["selected_horses"]
                    ]

                    # í‰ê°€
                    correct_count = len(set(predicted_horses) & set(actual_nums))
                    total_races += 1
                    total_correct_horses += correct_count

                    if correct_count == 3:
                        successful_predictions += 1
                        print("âœ… (3/3)")
                    elif correct_count == 2:
                        partial_correct_2 += 1
                        print("âš¡ (2/3)")
                    elif correct_count == 1:
                        partial_correct_1 += 1
                        print("ğŸ’« (1/3)")
                    else:
                        print("âŒ (0/3)")

                    # ê²°ê³¼ ì €ì¥
                    batch_results.append(
                        {
                            "race_id": race_id,
                            "predicted": predicted_horses,
                            "actual": actual_nums,
                            "correct_count": correct_count,
                            "confidence": prediction.get("confidence", 0),
                        }
                    )

                except subprocess.TimeoutExpired:
                    print("â±ï¸  (íƒ€ì„ì•„ì›ƒ)")
                except Exception as e:
                    print(f"âŒ ({type(e).__name__})")

                # API ì œí•œ ëŒ€ì‘
                time.sleep(2)

            # ë°°ì¹˜ ê²°ê³¼ ì €ì¥
            all_results.extend(batch_results)

            # ì¤‘ê°„ ì§„í–‰ ìƒí™© ì €ì¥
            progress = {
                "current_batch": i // batch_size + 1,
                "total_batches": (len(race_files) - 1) // batch_size + 1,
                "processed_races": total_races,
                "successful_predictions": successful_predictions,
                "partial_2": partial_correct_2,
                "partial_1": partial_correct_1,
                "current_success_rate": (
                    successful_predictions / total_races * 100 if total_races > 0 else 0
                ),
            }

            with open(progress_file, "w", encoding="utf-8") as f:
                json.dump(progress, f, ensure_ascii=False, indent=2)

            print(
                f"\ní˜„ì¬ê¹Œì§€: {total_races}ê²½ì£¼ ì²˜ë¦¬, {successful_predictions}íšŒ ì™„ì „ì ì¤‘ ({progress['current_success_rate']:.1f}%)"
            )

            # ë°°ì¹˜ ê°„ íœ´ì‹
            if i + batch_size < len(race_files):
                print("ë‹¤ìŒ ë°°ì¹˜ ì¤€ë¹„ ì¤‘...")
                time.sleep(5)

        # ìµœì¢… ê²°ê³¼ ì •ë¦¬
        summary = {
            "prompt_version": self.prompt_version,
            "evaluation_date": timestamp,
            "total_races": total_races,
            "total_files": len(race_files),
            "successful_predictions": successful_predictions,
            "partial_correct_2": partial_correct_2,
            "partial_correct_1": partial_correct_1,
            "no_correct": total_races
            - successful_predictions
            - partial_correct_2
            - partial_correct_1,
            "success_rate": (
                successful_predictions / total_races * 100 if total_races > 0 else 0
            ),
            "average_correct_horses": (
                total_correct_horses / total_races if total_races > 0 else 0
            ),
            "total_correct_horses": total_correct_horses,
            "detailed_results": all_results,
        }

        # ê²°ê³¼ ì €ì¥
        with open(results_file, "w", encoding="utf-8") as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)

        # ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
        report_file = self.results_dir / f"summary_report_{timestamp}.md"
        with open(report_file, "w", encoding="utf-8") as f:
            f.write("# ì „ì²´ ê²½ì£¼ í‰ê°€ ë³´ê³ ì„œ\n\n")
            f.write(
                f"- **í‰ê°€ ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            )
            f.write(f"- **í”„ë¡¬í”„íŠ¸ ë²„ì „**: {self.prompt_version}\n")
            f.write(f"- **ì „ì²´ ê²½ì£¼ íŒŒì¼**: {len(race_files)}ê°œ\n")
            f.write(f"- **ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬**: {total_races}ê°œ\n\n")
            f.write("## ì ì¤‘ í†µê³„\n\n")
            f.write("| êµ¬ë¶„ | ê²½ì£¼ ìˆ˜ | ë¹„ìœ¨ |\n")
            f.write("|------|---------|------|\n")
            f.write(
                f"| ì™„ì „ ì ì¤‘ (3/3) | {successful_predictions} | {successful_predictions / total_races * 100:.1f}% |\n"
            )
            f.write(
                f"| 2ë§ˆë¦¬ ì ì¤‘ (2/3) | {partial_correct_2} | {partial_correct_2 / total_races * 100:.1f}% |\n"
            )
            f.write(
                f"| 1ë§ˆë¦¬ ì ì¤‘ (1/3) | {partial_correct_1} | {partial_correct_1 / total_races * 100:.1f}% |\n"
            )
            f.write(
                f"| ë¯¸ì ì¤‘ (0/3) | {total_races - successful_predictions - partial_correct_2 - partial_correct_1} | {(total_races - successful_predictions - partial_correct_2 - partial_correct_1) / total_races * 100:.1f}% |\n"
            )
            f.write(
                f"\n**í‰ê·  ì ì¤‘ ë§ ìˆ˜**: {summary['average_correct_horses']:.2f}/3\n"
            )

        print("\n" + "=" * 60)
        print("ì „ì²´ í‰ê°€ ì™„ë£Œ!")
        print(f"ê²°ê³¼ íŒŒì¼: {results_file}")
        print(f"ìš”ì•½ ë³´ê³ ì„œ: {report_file}")

        return summary


def main():
    if len(sys.argv) < 3:
        print("Usage: python evaluate_all_races.py <prompt_version> <prompt_file>")
        print(
            "Example: python evaluate_all_races.py v2.1-optimized prompts/prediction-template-optimized.md"
        )
        sys.exit(1)

    prompt_version = sys.argv[1]
    prompt_file = sys.argv[2]

    # ì „ì²´ í‰ê°€ ì‹¤í–‰
    evaluator = FullEvaluator(prompt_version, prompt_file)
    race_files = evaluator.find_all_result_files()

    # í™•ì¸
    print(f"\nì „ì²´ {len(race_files)}ê°œ ê²½ì£¼ë¥¼ í‰ê°€í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
    print(f"ì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ {len(race_files) * 3 / 60:.1f}ì‹œê°„")
    response = input("ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")

    if response.lower() != "y":
        print("í‰ê°€ë¥¼ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
        return

    # í‰ê°€ ì‹¤í–‰
    evaluator.run_prediction_batch(race_files, batch_size=10)


if __name__ == "__main__":
    main()
